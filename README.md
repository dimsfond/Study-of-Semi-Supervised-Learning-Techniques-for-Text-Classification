# Semi-Supervised Learning for Text Classification

**Research & implementation of semi-supervised learning methods for text classification using Python, TensorFlow, scikit-learn, and BERT.**  
Includes Selfâ€‘Training, Coâ€‘Training, Clusterâ€‘thenâ€‘Label, and GANâ€‘BERT approaches to improve performance when labeled data is limited.

---

## ğŸ“ Repository Structure

| File / Notebook | Description |
|------------------|----------------------------|
| `SELF-TRAINING.ipynb` | Implementation and experiments for Selfâ€‘Training method |
| `CO-TRAINING.ipynb` | Implementation and experiments for Coâ€‘Training |
| `ClusterThenLabel.ipynb` | Experiments using clustering then labeling approach |
| `GAN-BERT.ipynb` | GANâ€‘BERT approach combining GAN and BERT for semi-supervised learning |
| `README.txt` | (Old / backup readme) |
| `LICENSE` | License file (GPLâ€‘3.0) |

---

## ğŸ§  Project Overview

Many NLP classification tasks (e.g. sentiment analysis, spam detection, hateâ€‘speech detection) require large annotated datasets, which are expensive to build. This project explores how **semi-supervised learning** can leverage a small amount of labeled data together with abundant unlabeled data, to improve classification performance.

The implemented methods are:

- **Selfâ€‘Training** â€” using a base model to label unlabeled data iteratively  
- **Coâ€‘Training** â€” two classifiers with different views teaching each other  
- **Clusterâ€‘thenâ€‘Label** â€” clustering data and propagating labels  
- **GANâ€‘BERT** â€” combining GAN architectures with BERT for semi-supervised classification  

These are compared to **fully supervised baselines** to evaluate gains, data efficiency, and robustness.

---

## ğŸ› ï¸ Tools & Technologies

- Python  
- Jupyter Notebooks  
- TensorFlow / Keras  
- scikit-learn  
- Hugging Face Transformers (BERT)  
- NumPy, pandas, matplotlib  

---

## Disclaimers
In the opening cells of every ipynb script, there are some cells that have
at the start comments which show what dataset will be downloaded and be processed
if we run this cell.

After these cells, there are explanations about certain lines of code as comments
